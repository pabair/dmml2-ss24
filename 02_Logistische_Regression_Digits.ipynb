{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression: Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook wollen wir anhand des Digits-Datensatzes Vorhersagen mit Hilfe einer logistischen Regression machen. In diesem Datensatz ist jeder Datenpunkt ein kleines Bild mit 8x8 Pixeln und stellt eine Ziffer zwischen 0 und 9 dar. Das Vorhersageproblem besteht darin, anhand der 64 Pixelwerte vorherzusagen um welche Zahl es sich handelt.\n",
    "Eine nähere Beschreibung der Daten findet sich [hier](https://scikit-learn.org/stable/datasets/toy_dataset.html#digits-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden des Digits-Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst Laden wir den `Digits`-Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/digits.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Datenpunkt hat 64 Features. Jedes Feature steht für ein Pixel in einem 8x8 Bild und hat einen Wert zwischen `0` und `16`, welcher der Graustufe des Pixels entspricht. Für den Wert `0` ist das Pixel komplett schwarz, während ein Wert von `16` einem weißen Pixel entspricht. Das Label eines Datenpunkts ist die abgebildete Ziffer.\n",
    "\n",
    "Die ersten 8 Features entsprechen den Pixeln der ersten Reihe des Bildes, die zweiten 8 Features der zweiten Reihe des Bildes usw.\n",
    "Um das besser zu veranschaulichen können wir die Daten des ersten Datenpunktes in eine 8x8-Form bringen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_no_label = data.drop([\"label\"], axis=1)\n",
    "line_1 = data_no_label.iloc[0].values\n",
    "np.reshape(line_1, (8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um uns testweise ein paar Bilder anzuschauen können wir ein paar zufällig ausgewählte Datenpunkte mit Hilfe der `matplotlib`-Library plotten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "no_images = 15\n",
    "\n",
    "plt.figure(figsize=(no_images, 1))\n",
    "for index in range(0, no_images):\n",
    "    \n",
    "    # wähle zufälligen Datenpunkt aus\n",
    "    image_index = random.randint(0, data.shape[0])\n",
    "    features = data_no_label.iloc[image_index].values\n",
    "    features_8x8 = np.reshape(features, (8,8))\n",
    "    label = data.iloc[image_index][\"label\"]\n",
    "    \n",
    "    # plotte das 8x8 Bild\n",
    "    plt.subplot(1, no_images, index + 1)\n",
    "    plt.imshow(features_8x8, cmap=plt.cm.gray)\n",
    "    plt.title(label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binäre Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel ist es jetzt mit Hilfe der Features (Pixelwerte) das Label (die dargestellte Ziffer) vorherzusagen. Dazu wollen wir uns im ersten Schritt auf eine einfache binäre Klassifizierung beschränken und Vorhersagen ob auf dem Bild die Ziffer `0` zu sehen ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im ersten Schritt unterteilen wir die Daten in Trainings- und Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_no_label, data[\"label\"], test_size=0.2, random_state=0)\n",
    "print(\"Trainingsdatenpunkte:\", len(X_train))\n",
    "print(\"Testdatenpunkte:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Klassifierzung hinsichtlich der Ziffer `0` müssen wir das Label jedes Datenpunktes umwandeln, so dass gilt:\n",
    "- `Label \"1\"`: Die Ziffer ist eine `0`.\n",
    "- `Label \"0\"`: Die Ziffer ist keine `0` (d.h. alle andere Ziffern).\n",
    "\n",
    "Diese machen wir über folgende Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_binary(digit, labels):\n",
    "    binary_labels = []\n",
    "    for label in labels:\n",
    "        if(label == digit):\n",
    "            binary_labels.append(1)\n",
    "        else:\n",
    "            binary_labels.append(0)\n",
    "    return np.array(binary_labels)\n",
    "    \n",
    "y_train_0 = label_to_binary(0, y_train)\n",
    "y_test_0 = label_to_binary(0, y_test)\n",
    "\n",
    "print(\"Alte Labels:\", y_train[:20].values)\n",
    "print(\"Neue Labels:\", y_train_0[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir das logistische Regressionsmodell trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression(max_iter=1000) # Gradient Descent mit max. 1000 Schritten\n",
    "logisticRegr.fit(X_train, y_train_0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen des Regressionsmodells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns nun zwei Beispiele aus den Testdaten und die dazugehörige Vorhersage an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "data_point = X_test.iloc[[data_index]]\n",
    "prediction = logisticRegr.predict(data_point)\n",
    "print(\"Vorhersage auf Datenpunkt\", data_index, \"ist:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell sagt die Klasse `0` vorraus (d.h. dass nicht die Ziffer 0 abgebildet ist). Schauen wir uns das richtige Label und den zugehörigen Plot an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.imshow(np.reshape(data_point.values, (8,8)), cmap=plt.cm.gray)\n",
    "plt.title(f'Ziffer: {y_test.iloc[data_index]}', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Vorhersage ist richtig (es ist nicht die Ziffer 0 auf dem Bild dargestellt).\n",
    "Schauen wir uns ein zweites Beispiel an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 17\n",
    "data_point = X_test.iloc[[data_index]]\n",
    "prediction = logisticRegr.predict(data_point)\n",
    "print(\"Vorhersage auf Datenpunkt\", data_index, \"ist:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.imshow(np.reshape(data_point.values, (8,8)), cmap=plt.cm.gray)\n",
    "plt.title(f\"Ziffer: {y_test.iloc[data_index]}\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Fall sagt das Modell die Klasse `1` (= es ist eine Null auf dem Bild zu sehen) voraus und es ist auch tatsächlich eine `0` auf dem Bild, d.h. das Modell liegt richtig. \n",
    "\n",
    "Schauen wir uns die Performance auf allen Testdaten an. Dazu mache wir zuerst eine Vorhersage mit dem Modell auf allen Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt vergleich wir diese Vorhersagen mit dem wahren Label und berechnen die Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_0, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Accuracy liegt bei diesem einfachen Modell bei 99 Prozent. Schauen wir uns Precision und Recall an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test_0, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test_0, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell erkennt alle Nullen im Testdatensatz und ist dabei 93% präzise.\n",
    "Es scheint also, dass das Problem eine Null in diesem Datensatz zu erkennen nicht sehr schwierig ist.\n",
    "\n",
    "Da wir jedoch keine 100% Precision erreicht haben, macht das Modell noch ein paar Fehler. Schauen wir uns exemplarisch einen Fehler an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 117\n",
    "data_point = X_test.iloc[[data_index]]\n",
    "prediction = logisticRegr.predict(data_point)\n",
    "print(\"Vorhersage auf Datenpunkt\", data_index, \"ist:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.imshow(np.reshape(data_point.values, (8,8)), cmap=plt.cm.gray)\n",
    "plt.title(\"Ziffer: \" + str(y_test.iloc[data_index]), fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Zwei hält das Modell fälschlicherweiße für eine Null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim gerade trainierten Modell können wir uns jetzt noch die Feature-Importance anschauen, d.h. die Gewichte welche das Modell für die einzelnen Pixel gelernt hat anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = logisticRegr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_8x8 = np.round(np.reshape(weights, (8,8)), decimals=3)\n",
    "weights_8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weights_8x8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Plot stehen grüne Fläche für ein Gewicht in der Nähe von 0, d.h. diese Pixel sind relativ irrelevant für die Klassifikation des Modells.\n",
    "Gelbe Flächen stehen für positive Gewichte, d.h. ein positiver Pixelwert an dieser Stelle lässt das Modell eher in Richtung 0 tendieren.\n",
    "Dunkle Flächen stehen für negative Gewichte, d.h. ein positiver Pixelwert an dieser Stelle lässt das Modell eher in Richting \"keine 0\" tendieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiklassen-Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt erweitern wir das Vorhersagemodell dahingehend, dass wir alle Ziffern erkennen wollen. Dies geschieht mit einer multinominalen logistischen Regression.\n",
    "\n",
    "Dazu trainieren wir individuelle Modell für jede Ziffer von 0 bis 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(0,10):\n",
    "    logisticRegr = LogisticRegression(max_iter=1000)\n",
    "    y_train_binary = label_to_binary(i, y_train)\n",
    "    logisticRegr.fit(X_train, y_train_binary)\n",
    "    models.append(logisticRegr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Modell nutzen wir jetzt bei der Vorhersage, in dem wir mit jedem Modell eine Vorhersage auf ein gegebens Bild machen und uns für die Vorhersage mit der höchsten Wahrscheinlichkeit entscheiden. Dazu brauchen wir (anstelle der vorhergesagten Klasse) die Vorhersagewahrscheinlichkeit eines Modells. Generell können wir mit der Methode `predict` direkt die Vorhersage der Klasse bekommen, während die `predict_proba`-Methode uns die Wahrscheinlichkeiten liefert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = X_test.iloc[[0]]\n",
    "predicted_class = logisticRegr.predict(data_point)\n",
    "print(\"Vorhergesagte Klasse:\", predicted_class)\n",
    "\n",
    "probability = logisticRegr.predict_proba(data_point)\n",
    "print(probability)\n",
    "print(\"Wahrscheinlichkeit für Klasse 1:\", probability[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den trainierten Einzelmodellen können wir nun für einen Datenpunkt vorhersagen mit allen 10 Modell machen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 34\n",
    "predictions = []\n",
    "for index, model in enumerate(models):\n",
    "    data_point = X_test.iloc[[data_index]]\n",
    "    prediction = model.predict_proba(data_point)[0][1]\n",
    "    print(\"Vorhersage mit Modell für Ziffer\", index, \"ist\", prediction)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und die Klasse vorhersagen welche die höchste Wahrscheinlichkeit hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictions.index(max(predictions))\n",
    "print(\"Vorhergesagte Klasse:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.imshow(np.reshape(X_test.iloc[data_index].values, (8,8)), cmap=plt.cm.gray)\n",
    "plt.title(f\"Ziffer: {y_test.iloc[data_index]}\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir sehen stimmt die vorhergesagte Ziffer in diesem Fall mit der tatsächlichen Ziffer überein. Im nächsten Schritt schauen wir uns die Vorhersage über alle Testdatenpunkte an und schauen auf die Accuarcy.\n",
    "Dazu sagen wir mit jedem der 10 Modelle auf jedem Testdatenpunkt vorher, und merken uns die Klasse mit der höchsten Wahrscheinlichkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "for data_index in range(0, len(X_test)):\n",
    "    data_point = X_test.iloc[[data_index]]\n",
    "    predictions = []\n",
    "    for model in models:  \n",
    "        prediction = model.predict_proba(data_point)[0][1]\n",
    "        predictions.append(prediction)\n",
    "    predicted_class = predictions.index(max(predictions))\n",
    "    test_predictions.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir sehen können wir mit unserem recht simplen Modell bereits 95% der Fälle richtig vorhersagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Schluss schauen wir uns die Confusion Matrix der einzelnen Fälle an und den Classificatin Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, test_predictions, labels=range(0,10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(0,10))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Schluss schauen wir uns den Fall an, wenn wir direkt auf allen Labels trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(max_iter=10000)\n",
    "logReg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, logReg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wir sehen kann die Klasse `LogisticRegression` auch direkt mit mehreren Labels umgehen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
