{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe633a53",
   "metadata": {},
   "source": [
    "# 7. Transfer Learning for CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f04e7",
   "metadata": {},
   "source": [
    "In this notebook we load a small datasets that contains pictures of dolphins and elephants. We classify the images using CNNs and compare two approaches to see what works better:\n",
    "1. Training a CNN from scratch.\n",
    "2. Finetuning a pretrained ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9347627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8fab59c4b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ce7b5",
   "metadata": {},
   "source": [
    "Let's load our data and have a look at the shape of some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0508c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=RGB size=300x179 at 0x7F8FA982ADF0>, 0)\n",
      "(<PIL.Image.Image image mode=RGB size=300x179 at 0x7F8FA982AB20>, 0)\n",
      "(<PIL.Image.Image image mode=RGB size=300x166 at 0x7F8FA982A760>, 0)\n",
      "(<PIL.Image.Image image mode=RGB size=300x259 at 0x7F8FA982A580>, 0)\n",
      "(<PIL.Image.Image image mode=RGB size=300x225 at 0x7F8FA982ADF0>, 0)\n",
      "(<PIL.Image.Image image mode=RGB size=300x277 at 0x7F8FA982A550>, 0)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(root='./data/animals')\n",
    "for i, data in enumerate(dataset):\n",
    "    print(data)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4e264",
   "metadata": {},
   "source": [
    "We see that the pictures have all `width=300` but a varying height. To use them in transfer learning they need to have the standard shape of size `(224, 224)`, which is the data format of ImageNet (on which most pretrained models are trained on).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb2c83",
   "metadata": {},
   "source": [
    "To get them into this shape, we first define a transformation that increases the image height to 224 (this will also increase the width) and then take the 224 pixel center square of the picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551777c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "             transforms.Resize(size=224),\n",
    "             transforms.CenterCrop(size=224),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) # standard normalization for transfer learning\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bb05d-d7c8-4806-ba98-ba70115539f0",
   "metadata": {},
   "source": [
    "With this transformation, we now load all images from the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e3626",
   "metadata": {},
   "source": [
    "Next, we split the data into train and test and define the data loaders that loads the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d1ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.ImageFolder(root='./data/animals', transform=image_transforms)\n",
    "train_set, test_set = torch.utils.data.random_split(data, [100, 29])\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=29,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bce70",
   "metadata": {},
   "source": [
    "## Tasks:\n",
    "### Task 1.\n",
    "Train a CNN from scratch to identify the object on the image (dolphin or elephant). For this, use the same CNN architecture as in cell 7 of the notebook from last week `06_CNNs.ipynb`. To make this work, here are a few things you need to change:\n",
    "1. You need to change the input size of the fully-connected layer to match the new image dimension.\n",
    "2. You need to change the output dimension of the fully-connected layer to classify only two classes instead of ten.\n",
    "3. We now used a dataloader to load the data (see cell above), which allows us to train our model in mini-batches (aka \"mini-batch gradient descent\"). You can see [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#train-the-network), how you can train the network using mini-batches given the `trainloader` from above.  \n",
    "\n",
    "Train for 20 epochs on the train data and afterwards compute the accuracy on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd04a89",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "Instead of training a CNN from scratch, we now want to load a pretrained **ResNet18** model and re-train its last layer to do our classifcation task.\n",
    "PyTorch has a [tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor) on transfer learning, which you can check to see how this works (note: its enough to read the section `ConvNet as fixed feature extractor`).\n",
    "\n",
    "Train the last layer of the pre-trained RestNet model for 20 epochs and compare the results to task 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
